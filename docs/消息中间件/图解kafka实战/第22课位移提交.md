# 1、offset和offset

我们私下约定好：
* 生产者的offset叫偏移量
* 消费者的offset叫位移

有3个offset要关注下：
* consumed offset = x，表示消费到哪里了
* commit offset = x + 1， 表示客户端提交到哪里了
* position = x + 1，表示下一次要从哪里开始消费

# 2、自动提交和手动提交

自动提交：
* enable.auto.commit = true， 默认是true
* auto.commit.interval.ms = 5000， 默认5秒自动提交一次

手动提交：
* commitSync
* commitAsync


# 3、同步提交和异步提交

手动提交又分为：
* 同步提交 commitSync
* 异步提交 commitAsync

## 3.1、手动提交中的同步提交
```
//循环消费消息
while (true) {
    ConsumerRecords<String, String> records =
            consumer.poll(Duration.ofMillis(1000));
    for (ConsumerRecord<String, String> record : records) {
        System.out.println(record.value());
    }
    consumer.commitAsync();
}
```

也可以批量：
```
//循环消费消息
while (true) {
    ConsumerRecords<String, String> records =
            consumer.poll(Duration.ofMillis(1000));
    List<ConsumerRecord<String, String>> buffer = new ArrayList<>(200);
    for (ConsumerRecord<String, String> record : records) {
        System.out.println(record.value());
        buffer.add(record);
    }
    if (buffer.size() >= 200) {
        consumer.commitAsync();
        buffer.clear();
    }
}
```
手动同步提交，当消费者宕机，会遇到`消息重复消费`的情况，不过国哥认为能接受，做好消息幂等性或者第三方存储帮忙存offset进度，均可。

## 3.2、手动提交中的异步提交
```
//循环消费消息
while (true) {
    ConsumerRecords<String, String> records =
            consumer.poll(Duration.ofMillis(1000));
    for (ConsumerRecord<String, String> record : records) {
        System.out.println(record.value());
    }
    consumer.commitAsync(
            new OffsetCommitCallback() {
                @Override
                public void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets, Exception exception) {
                    if (exception == null){
                        System.out.println("commit aysnc ok: " + offsets);
                    }else{
                        System.out.println("fail to commit offset:"+offsets+", "+exception);
                    }
                }
            }
    );
}
```

# 4、生产环境最佳实践
这里我就直接`拿来主义`啦，参考第二篇引用：
```
在大家日常的使用中，我常常发现很多业务都是消费一条消息就提交一个 offset，导致\\consumer\_offsets 的消息写入量非常高。这里总结了两个最佳的消费组提交 offset 的最佳实践。大家看了之后回去可以进行修改一下代码。

 容忍重复消费场景
    -   采用自动提交
    -   批量处理完成消息后手动提交最大的偏移量

 手动提交场景
    -   消息量小
    -   消息不容丢失
    -   消息不容重复消费
    -   对性能要求不高

```



# 5、参考
* [某互联网大厂kafka最佳实践](https://www.jianshu.com/p/8689901720fd)
* [Kafka 设计实现与最佳实践之客户端篇](https://xie.infoq.cn/article/b15e3cf54096172bee0ecace6)
* [上面的消费者代码传送门](https://github.com/fatpo/kafka-demo/tree/main/kakfa/src/main/java)