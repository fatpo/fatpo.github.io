# 1、客户端也有拦截器
先定制一个拦截器：
```java
import org.apache.kafka.clients.consumer.ConsumerInterceptor;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.OffsetAndMetadata;
import org.apache.kafka.common.TopicPartition;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

public class ConsumerInterceptorTTL implements ConsumerInterceptor<String, String> {
    public static final Integer EXPIRE_INTERVAL = 10 * 1000;

    @Override
    public ConsumerRecords<String, String> onConsume(ConsumerRecords<String, String> records) {
        System.out.println("onConsume...before: " + records);

        long now = System.currentTimeMillis();
        Map<TopicPartition, List<ConsumerRecord<String, String>>> newRecords = new HashMap<>();

        for (TopicPartition tp : records.partitions()) {
            List<ConsumerRecord<String, String>> tpRecords = records.records(tp);
            List<ConsumerRecord<String, String>> newTpRecords = new ArrayList<>(8);
            for (ConsumerRecord<String, String> r : tpRecords) {
                if (now - r.timestamp() < EXPIRE_INTERVAL) {
                    newTpRecords.add(r);
                }
            }
            if (!newTpRecords.isEmpty()) {
                newRecords.put(tp, newTpRecords);
            }
        }
        System.out.println("onConsume...after: " + newRecords);
        return new ConsumerRecords<>(newRecords);
    }

    @Override
    public void onCommit(Map<TopicPartition, OffsetAndMetadata> offsets) {
        offsets.forEach((tp, offset) -> System.out.println("committed: " + tp + " : " + offset.offset()));
    }

    @Override
    public void close() {

    }

    @Override
    public void configure(Map<String, ?> configs) {

    }
}
```

消费端客户端增加拦截器的配置：
```text
properties.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, ConsumerInterceptorTTL.class.getName());
```

# 2、生产者模拟发送过期消息
创建消息，可以指定时间戳，这里我们模拟时间过期了：
```text
ProducerRecord<String, String> record1 =
                new ProducerRecord<>(topic, 0, System.currentTimeMillis() - 11 * 1000, null, "record 1");
        
```
一共发送3个消息，其中`record1`和`record3`，这两个失去了时效，`record2`是正常的时间戳：
```java
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;

import java.util.Properties;
import java.util.concurrent.ExecutionException;

public class ProducerDemoV7WithConsumerInterceptorTTL {
    public static final String brokerList = "1.116.156.79:9092";
    public static final String topic = "test2";

    public static void main(String[] args) throws ExecutionException, InterruptedException {
        Properties properties = new Properties();
        properties.put("key.serializer",
                "org.apache.kafka.common.serialization.StringSerializer");
        properties.put("value.serializer",
                "org.apache.kafka.common.serialization.StringSerializer");
        properties.put("bootstrap.servers", brokerList);

        System.out.println("send a message: hello, Kafka!");
        KafkaProducer<String, String> producer =
                new KafkaProducer<>(properties);

        ProducerRecord<String, String> record1 =
                new ProducerRecord<>(topic, 0, System.currentTimeMillis() - 11 * 1000, null, "record 1");
        producer.send(record1).get();

        ProducerRecord<String, String> record2 =
                new ProducerRecord<>(topic, 0, System.currentTimeMillis(), null, "record 2");
        producer.send(record2).get();

        ProducerRecord<String, String> record3 =
                new ProducerRecord<>(topic, 0, System.currentTimeMillis() - 11 * 1000, null, "record 3");
        producer.send(record3).get();

        producer.close();
    }
}
```

# 3、拦截器效果
类似ttl队列，把一些失去了时效性的消息过滤掉。
```text
onConsume...before: org.apache.kafka.clients.consumer.ConsumerRecords@14c50bc
onConsume...after: {}
onConsume...before: org.apache.kafka.clients.consumer.ConsumerRecords@84a914
onConsume...after: {test2-0=[ConsumerRecord(topic = test2, partition = 0, offset = 41, CreateTime = 1631113159061, serialized key size = -1, serialized value size = 8, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = record 2)]
onConsume...before: org.apache.kafka.clients.consumer.ConsumerRecords@10378a4
onConsume...after: {}
```

