# 1、分区器的作用
国哥就7个字总结：`自定义分区规则`。

# 2、默认分区器怎么玩
默认分区器是：`org.apache.kafka.clients.producer.internals.DefaultPartitioner`，
不过只要你实现了`org.apache.kafka.clients.producer.Partitioner `接口，就是一个合格的分区器。
```text
public int partition(String topic, Object key, byte[] keyBytes, 
                     Object value, byte[] valueBytes, Cluster cluster);
public void close();
```
kafka默认的分区器代码：
```java
public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
    List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
    int numPartitions = partitions.size();
    if (keyBytes == null) {
        int nextValue = nextValue(topic);
        List<PartitionInfo> availablePartitions = cluster.availablePartitionsForTopic(topic);
        if (availablePartitions.size() > 0) {
            int part = Utils.toPositive(nextValue) % availablePartitions.size();
            return availablePartitions.get(part).partition();
        } else {
            // no partitions are available, give a non-available partition
            return Utils.toPositive(nextValue) % numPartitions;
        }
    } else {
        // hash the keyBytes to choose a partition
        return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
    }
}
```
代码很简单，如果有key则用murmur2 hash算法，如果没有key则拿到topic对应的计数器AtomicInteger，用计数器来做+1取模。

`nextValue()`代码:
```java
private int nextValue(String topic) {
    AtomicInteger counter = topicCounterMap.get(topic);
    if (null == counter) {
        counter = new AtomicInteger(ThreadLocalRandom.current().nextInt());
        AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter);
        if (currentCounter != null) {
            counter = currentCounter;
        }
    }
    return counter.getAndIncrement();
}
```


# 3、自定义分区器
参考默认的分区器，我们实现一个自己的：
```java
import org.apache.kafka.clients.producer.Partitioner;
import org.apache.kafka.common.Cluster;
import org.apache.kafka.common.PartitionInfo;
import org.apache.kafka.common.utils.Utils;

import java.util.List;
import java.util.Map;
import java.util.concurrent.atomic.AtomicInteger;

public class DemoPartitioner implements Partitioner {
    private final AtomicInteger counter = new AtomicInteger(0);

    @Override
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
        List<PartitionInfo> partitionInfos = cluster.partitionsForTopic(topic);
        int numPartitions = partitionInfos.size();

        // 当没有key时，是没办法分区的，要依赖业务定制
        if (keyBytes == null) {
            return counter.getAndIncrement() % numPartitions;
        }
        return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
    }

    @Override
    public void close() {

    }

    @Override
    public void configure(Map<String, ?> configs) {

    }
}
```
生产者怎么配置分区器：
```java
// 分区器
properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, DemoPartitioner.class.getName());
```
完整配置：
```java
public static Properties initConfig() {
    Properties properties = new Properties();
    // 诸如“key.serializer”、“max.request.size”、“interceptor.classes”之类的字符串经常由于人为因素而书写错误
    // kafka 帮我们提供了一些constant常量
    properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);
    properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,
            "org.apache.kafka.common.serialization.StringSerializer");
    properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
            "org.apache.kafka.common.serialization.StringSerializer");
    properties.put(ProducerConfig.CLIENT_ID_CONFIG, "producer.client.id.demo");

    // 重试次数
    properties.put(ProducerConfig.RETRIES_CONFIG, 10);
    // 拦截器
    properties.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,
            ProducerInterceptorPrefix1.class.getName() + "," + ProducerInterceptorPrefix2.class.getName());
    // 分区器
    properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, DemoPartitioner.class.getName());
    return properties;
}
```
结果：
```text
"D:\Program Files (x86)\Java\jdk1.8.0_111\bin\java.exe" "-javaagent:C:\Program Files\JetBrains\IntelliJ IDEA 2020.1\lib\idea_rt.jar=53187:C:\Program Files\JetBrains\IntelliJ IDEA 2020.1\bin" -Dfile.encoding=UTF-8 -classpath "D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\charsets.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\deploy.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\ext\access-bridge-32.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\ext\cldrdata.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\ext\dnsns.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\ext\jaccess.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\ext\jfxrt.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\ext\localedata.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\ext\nashorn.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\ext\sunec.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\ext\sunjce_provider.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\ext\sunmscapi.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\ext\sunpkcs11.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\ext\zipfs.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\javaws.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\jce.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\jfr.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\jfxswt.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\jsse.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\management-agent.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\plugin.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\resources.jar;D:\Program Files (x86)\Java\jdk1.8.0_111\jre\lib\rt.jar;D:\IdeaProjects\kafka-demo\kakfa\target\classes;D:\maven\repository\org\apache\kafka\kafka-clients\2.0.0\kafka-clients-2.0.0.jar;D:\maven\repository\org\lz4\lz4-java\1.4.1\lz4-java-1.4.1.jar;D:\maven\repository\org\xerial\snappy\snappy-java\1.1.7.1\snappy-java-1.1.7.1.jar;D:\maven\repository\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar" ProducerDemoV6Partitioner
send a message: hello, Kafka!
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
分区到：0
分区到：1
[send callback -2] topic: test2, partition: 1, offset: 15
[send callback -1] topic: test2, partition: 0, offset: 10
interceptor1 send success:2, send failure:0
interceptor2 send success:2, send failure:0

Process finished with exit code 0

```

[GIT完整代码](https://github.com/fatpo/kafka-demo/blob/main/kakfa/src/main/java/ProducerDemoV6Partitioner.java)