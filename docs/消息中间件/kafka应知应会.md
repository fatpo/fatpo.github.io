# 看完这kafka笔记后我应该掌握

* **怎么提高kafka消费者的消费能力？**
  * 陷阱：
    * 往消费组里面添加消费者，可行吗？不一定可行，当消费组内的消费者数量小于分区数量，添加消费者有用，达到分区数量后就没用了。最极限的情况就是一个组的每一个消费者专门盯着一个分区，一对一盯防。
  * 正确做法：
    * 1、在合理范围内，提升分区的数量，比如从3个提升到16个这样子，分区数量是消费者数量的天花板。控制变量的情况下，消费者越多，消费能力越高。
    * 2、没批量上批量， max.poll.records 配置可以控制。
    * 3、有批量拉取的情况下，检查批量发送消息的大小是否过大？检查消息发送间隙是否过小？批量是个好东西，但是要防止一次性拉取太多消息，消费不过来，更可怕的是kafka会踢掉这个消费过久的消费者，以为它挂了，再另外分配消费者，这是恶性循环。
    * 4、如果可以的话，提升消费者机器性能。
* **怎么避免消息丢失？**
    * 1、producer端丢失：
        * 原因：
            * 瞬时错误：重试即可。
            * 格式错误：调整格式后再次发送即可。
        * 正确做法： 
            * 1、用producer.send(msg, callback) 替代 producer.send(msg)，不能"fire and forget"，发送失败针对性处理即可。
            * 2、retries配置可以设置较大的值，出现问题会重试。
    * 2、broker端丢失：
        * 原因：
            * 1、Kafka 为了提高吞吐量和性能，采用异步批量的刷盘策略，也就是按照一定的消息量和间隔时间进行刷盘。
            * 2、Kafka 收到消息后会先存储在也缓存中(Page Cache)中，之后由操作系统根据自己的策略进行刷盘或者通过 fsync 命令强制刷盘。如果系统挂掉，在 PageCache 中的数据就会丢失。（一般副本都分布在多台机器，多台机器同时宕机的情况不考虑哈）
        * 正确做法：
            * 1、了解kafka的acks机制，是producer端配置的一个参数。
                * 1.1、acks=0，producer端无脑发送数据到broker，无需broker确认ack。
                * 1.2、acks=1，producer端发送数据到broker后，需要等待leader的ack后才算发送成功。
                * 1.3、acks=-1，需要分区内所有的副本都成功写入，才通知producer发送成功。（如果分区只有1个副本就退化成ack=1）
            * 2、按照业务所需，选择合理的acks，如果一定要百分百不丢失，就要保证acks=-1以及分区副本大于1个。
    * 3、consumer端丢失：
        * 唯一原因：拉取了消息，还没消费，就提交了offset。
        * 正确做法：取消自动提交，拉取消息后，处理完毕，再手动提交。
* **怎么避免消息重复消费？**
  * 原因：
    * 原因1：当自动提交时，假设5秒自动提交一次。我在第0秒完成第一次自动提交，要在第5秒的时候才能第二次自动提交。此时消费者消费到第3秒的时候，发生了再均衡，触发了消息重新pull，此时拉取的offset是第一次提交后返回的位移。意味着这0-3秒的消息要再消费一次。
    * 原因2：宕机、强行kill了线程，导致消费后的数据，没有提交offset。
    * 原因3:（重复消费最常见的原因）消费后的数据，当offset还没有提交时，partition就断开连接。比如，通常会遇到消费的数据，处理很耗时，导致超过了Kafka的session timeout时间（0.10.x版本默认是30秒），那么就会re-blance重平衡，此时有一定几率offset没提交，会导致重平衡后重复消费。
    * 原因4：当消费者重新分配partition的时候，可能出现从头开始消费的情况，导致重发问题。
    * 原因5：当消费者消费的速度很慢的时候，可能在一个session周期内还未完成，导致心跳机制检测报告出问题。
    * 原因6：并发很大，可能在规定的时间（session.time.out默认30s）内没有消费完，就会可能导致reblance重平衡，导致一部分offset自动提交失败，然后重平衡后重复消费
  * 问题剖析：
    * 这个无论你是自动提交还是手动提交，遇到了宕机、再均衡，你就有可能重复消费，所以问题无解。
    * 我们应该把思路转到怎么处理消息的幂等性。
  * 正确做法：（结合业务）
    * 1、如果是redis重复set，无视幂等性，因为redis天然幂等。
    * 2、如果是插入db，可以用唯一key约束，insert前检查id是否存在。
    * 3、再复杂一些的设计就是，弄一个类似messageId的东西，存到redis，每次消费的时候看看redis是否存在messageId，存在就放弃消费。没存在就消费，消费后把messageId写入redis。
* **如何降低消息消费的延迟？**
    * 这个和"怎么提高kafka的消费能力"是同一个问题。
* **如果保证消息的顺序性？**
    * 全局有序：
        * 描述：一个topic下的所有消息都严格按照生产顺序消费。
        * 做法：kafka只能一个topic只能有一个分区。消费者只能单线程消费。
    * 局部有序：
        * 描述：一个topic下的消息，保证满足同一个业务字段的按照生产顺序消费，比如订单id相同的消息，按照生产顺序消费。
        * 做法：对同一个业务字段的消息进行Partition key指定，保证局部消息进入同一个分区，然后被一个消费者消费。消费者也只能单线程消费。
    * 消息重发怎么办：
        * 描述：本来生产者按照ABC顺序发送消息，结果A发送失败了，重试后顺序变成了BCA，这就打乱了顺序。
        * 做法：max.in.flight.requests.per.connection=1，该参数指定了生产者在收到服务器响应之前可以发送多少个消息。它的值越高，就会占用越多的内存，同时也会提升吞吐量。把它设为1就可以保证消息是按照发送的顺序写入服务器的。但是设置为1很严重吞吐哦！！！
* **为什么kafka要设计消费组？**
    * 消费组特性：
        * 一个分区只可以被消费组中的一个消费者所消费。
    * 消费组优点：
        * 高性能：
            * 如果有10个分区要消费，只有一个消费者跟不上消费节奏时，可以增加消费者到这个分组，进而提高消费能力（上限是10个消费者）。
            * 这里提示我们，如果可能的话，可以把分区数量提升，便于后期增加消费者提升性能。
        * 消费模式灵活：
            * 如果有多个消费组，一个消费组只有一个消费者，那么就等于（广播）发布订阅模式
            * 如果只有1个消费组，组内有多个消费者，那么就等于（单播）队列模式。
        * 便于故障容灾：
            * 如果只有一个消费者，出现故障就麻烦了。但如果有一个消费组，消费者的加入或退出，都会触发再均衡操作，把那个出错的消费者的分区分给别的正常消费者。
* **什么是kafka消息再均衡？**
    * 设计初衷：
        * 应对这个世界的变化。消费者会宕机，新的消费者会加入，消费者会掉线等等。
    * 触发时机:
        * 消费者数量的变化：新增、减少
        * 分区数量的变化：新增（只能新增）
        * 主题创建，当消费者订阅主题时使用的是正则表达式，例如“test.*”，表示订阅所有以test开头的主题，当有新的以test开头的主题被创建时，则需要通过再均衡将该主题的分区分配给消费者。
    * 协调者：
        * 每一个broker都有一个专门的协调者组件，为消费组服务。
        * 确定broker：计算分区号、找出分区leader副本所在的分区
    * 交互方式：
        * 心跳机制
        * 重要参数：
            * session.timeout.ms：Broker端参数，消费者的存活时间，默认10秒，如果在这段时间内，协调者没收到任何心跳，则认为该消费者已崩溃离组；
            * heartbeat.interval.ms：消费者端参数，发送心跳的频率，默认3秒；
            * max.poll.interval.ms：消费者端参数，两次调用poll的最大时间间隔，默认5分钟，如果5分钟内无法消费完，则会主动离组。
* **为什么说分区数量就是消费者的最大数量？**
* **kafka提交方式的最佳实践是什么?**
* **如何处理kafka的消息堆积？**
* **万亿级别的kafka怎么保证高性能、高可用、高吞吐？**