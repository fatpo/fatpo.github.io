# 看完kafka笔记后我应该掌握

* **怎么提高kafka消费者的消费能力？**
* **如何降低消息消费的延迟？**
* **怎么避免消息丢失？**
* **怎么避免消息重复消费？**
* **如果保证消息的顺序性？**
* **为什么kafka要设计消费组？**
* **什么是kafka消息再均衡？**
* **如何避免消费组ReBalance？**
* **为什么说分区数量就是消费者的最大数量？**
* **kafka提交方式的最佳实践是什么?**
* **如何处理kafka的消息堆积？**
* **kafka的三种消息投递语义？**
* **kafka怎么保证高性能、高可用、高吞吐？**


## 怎么提高kafka消费者的消费能力？
  * 陷阱：
    * 往消费组里面添加消费者，可行吗？不一定可行，当消费组内的消费者数量小于分区数量，添加消费者有用，达到分区数量后就没用了。最极限的情况就是一个组的每一个消费者专门盯着一个分区，一对一盯防。
  * 正确做法：
    * 1、在合理范围内，提升分区的数量，比如从3个提升到16个这样子，分区数量是消费者数量的天花板。控制变量的情况下，消费者越多，消费能力越高。
    * 2、没批量上批量， max.poll.records 配置可以控制。
    * 3、有批量拉取的情况下，检查批量发送消息的大小是否过大？检查消息发送间隙是否过小？批量是个好东西，但是要防止一次性拉取太多消息，消费不过来，更可怕的是kafka会踢掉这个消费过久的消费者，以为它挂了，再另外分配消费者，这是恶性循环。
    * 4、如果可以的话，提升消费者机器性能。

## 如何降低消息消费的延迟？
* 这个和"怎么提高kafka的消费能力"是同一个问题。

## 怎么避免消息丢失？
* 1、producer端丢失：
    * 原因：
        * 瞬时错误：重试即可。
        * 格式错误：调整格式后再次发送即可。
    * 正确做法： 
        * 1、用producer.send(msg, callback) 替代 producer.send(msg)，不能"fire and forget"，发送失败针对性处理即可。
        * 2、retries配置可以设置较大的值，出现问题会重试。
* 2、broker端丢失：
    * 原因：
        * 1、Kafka 为了提高吞吐量和性能，采用异步批量的刷盘策略，也就是按照一定的消息量和间隔时间进行刷盘。
        * 2、Kafka 收到消息后会先存储在也缓存中(Page Cache)中，之后由操作系统根据自己的策略进行刷盘或者通过 fsync 命令强制刷盘。如果系统挂掉，在 PageCache 中的数据就会丢失。（一般副本都分布在多台机器，多台机器同时宕机的情况不考虑哈）
    * 正确做法：
        * 1、了解kafka的acks机制，是producer端配置的一个参数。
            * 1.1、acks=0，producer端无脑发送数据到broker，无需broker确认ack。
            * 1.2、acks=1，producer端发送数据到broker后，需要等待leader的ack后才算发送成功。
            * 1.3、acks=-1，需要分区内所有的副本都成功写入，才通知producer发送成功。（如果分区只有1个副本就退化成ack=1）
        * 2、按照业务所需，选择合理的acks，如果一定要百分百不丢失，就要保证acks=-1以及分区副本大于1个。
* 3、consumer端丢失：
    * 唯一原因：拉取了消息，还没消费，就提交了offset。
    * 正确做法：取消自动提交，拉取消息后，处理完毕，再手动提交。

## 怎么避免消息重复消费？
  * 原因：
    * 原因1：当自动提交时，假设5秒自动提交一次。我在第0秒完成第一次自动提交，要在第5秒的时候才能第二次自动提交。此时消费者消费到第3秒的时候，发生了再均衡，触发了消息重新pull，此时拉取的offset是第一次提交后返回的位移。意味着这0-3秒的消息要再消费一次。
    * 原因2：宕机、强行kill了线程，导致消费后的数据，没有提交offset。
    * 原因3:（重复消费最常见的原因）消费后的数据，当offset还没有提交时，partition就断开连接。比如，通常会遇到消费的数据，处理很耗时，导致超过了Kafka的session timeout时间（0.10.x版本默认是30秒），那么就会re-blance重平衡，此时有一定几率offset没提交，会导致重平衡后重复消费。
    * 原因4：当消费者重新分配partition的时候，可能出现从头开始消费的情况，导致重发问题。
    * 原因5：当消费者消费的速度很慢的时候，可能在一个session周期内还未完成，导致心跳机制检测报告出问题。
    * 原因6：并发很大，可能在规定的时间（session.time.out默认30s）内没有消费完，就会可能导致reblance重平衡，导致一部分offset自动提交失败，然后重平衡后重复消费
  * 问题剖析：
    * 这个无论你是自动提交还是手动提交，遇到了宕机、再均衡，你就有可能重复消费，所以问题无解。
    * 我们应该把思路转到怎么处理消息的幂等性。
  * 正确做法：（结合业务）
    * 1、如果是redis重复set，无视幂等性，因为redis天然幂等。
    * 2、如果是插入db，可以用唯一key约束，insert前检查id是否存在。
    * 3、再复杂一些的设计就是，弄一个类似messageId的东西，存到redis，每次消费的时候看看redis是否存在messageId，存在就放弃消费。没存在就消费，消费后把messageId写入redis。

## 如果保证消息的顺序性？
* 全局有序：
    * 描述：一个topic下的所有消息都严格按照生产顺序消费。
    * 做法：kafka只能一个topic只能有一个分区。消费者只能单线程消费。
* 局部有序：
    * 描述：一个topic下的消息，保证满足同一个业务字段的按照生产顺序消费，比如订单id相同的消息，按照生产顺序消费。
    * 做法：对同一个业务字段的消息进行Partition key指定，保证局部消息进入同一个分区，然后被一个消费者消费。消费者也只能单线程消费。
* 消息重发怎么办：
    * 描述：本来生产者按照ABC顺序发送消息，结果A发送失败了，重试后顺序变成了BCA，这就打乱了顺序。
    * 做法：max.in.flight.requests.per.connection=1，该参数指定了生产者在收到服务器响应之前可以发送多少个消息。它的值越高，就会占用越多的内存，同时也会提升吞吐量。把它设为1就可以保证消息是按照发送的顺序写入服务器的。但是设置为1很严重吞吐哦！！！

## 为什么kafka要设计消费组？
* 消费组特性：
    * 一个分区只可以被消费组中的一个消费者所消费。
* 消费组优点：
    * 高性能：
        * 如果有10个分区要消费，只有一个消费者跟不上消费节奏时，可以增加消费者到这个分组，进而提高消费能力（上限是10个消费者）。
        * 这里提示我们，如果可能的话，可以把分区数量提升，便于后期增加消费者提升性能。
    * 消费模式灵活：
        * 如果有多个消费组，一个消费组只有一个消费者，那么就等于（广播）发布订阅模式
        * 如果只有1个消费组，组内有多个消费者，那么就等于（单播）队列模式。
    * 便于故障容灾：
        * 如果只有一个消费者，出现故障就麻烦了。但如果有一个消费组，消费者的加入或退出，都会触发再均衡操作，把那个出错的消费者的分区分给别的正常消费者。

## 什么是kafka消息再均衡？
* 设计初衷：
    * 应对这个世界的变化。消费者会宕机，新的消费者会加入，消费者会掉线等等。
* 触发时机:
    * 消费者数量的变化：新增、减少
    * 分区数量的变化：新增（只能新增）
    * 主题创建，当消费者订阅主题时使用的是正则表达式，例如“test.*”，表示订阅所有以test开头的主题，当有新的以test开头的主题被创建时，则需要通过再均衡将该主题的分区分配给消费者。
* 协调者：
    * 每一个broker都有一个专门的协调者组件，为消费组服务。
    * 确定broker：计算分区号、找出分区leader副本所在的分区
* 交互方式：
    * 心跳机制
    * 重要参数：
        * session.timeout.ms：Broker端参数，消费者的存活时间，默认10秒，如果在这段时间内，协调者没收到任何心跳，则认为该消费者已崩溃离组；
        * heartbeat.interval.ms：消费者端参数，发送心跳的频率，默认3秒；
        * max.poll.interval.ms：消费者端参数，两次调用poll的最大时间间隔，默认5分钟，如果5分钟内无法消费完，则会主动离组。

## 如何避免消费组ReBalance？
* ReBalance 就是让一个 Consumer Group 下所有的 Consumer 实例就如何消费订阅主题的所有分区达成共识的过程。
* 在整个过程中，所有实例都不能消费任何消息，因此它对 Consumer 的 TPS 影响很大。所以要尽可能避免再均衡。
* Consumer 处理业务超时了，消费组把 Consumer 踢出去了，业务设置重试机制，自动从线程池中拿出一个新线程作为消费者去订阅 topic，那么意味着有新消费者加入 Consumer Group，又会引发 Rebalance，新的消费者还是来不及处理完所有消息，又被移出 Consumer Group。如此循环，就发生了频繁的 Rebalance 现象。
* 时机：
    * 组成员数量发生变化（可以避免）
    * 订阅主题数量发生变化（运维主动操作，不用避免）
    * 订阅主题的分区数发生变化（运维主动操作，不用避免）
* 组成员数量发生变化：
    * 新增消费者，这个一般情况也是主动为之，为了增加TPS或者提高伸缩性的需求，不要去管。
    * 减少消费者：
        * 故意减少消费者：这个一般运维主动为之，不用避免。
        * kafka以为消费者挂了，踢掉消费者：（这个可以避免）
            * session.timeout.ms 设置了超时时间，默认10秒，10秒内没收到消费者心跳，broker就踢了它，触发再均衡。
            * heartbeat.interval.ms 心跳时间间隔，默认3秒，一般是 1/3 * session.timeout.ms，发送心跳的时间，配合 session.timeout.ms使用。
            * max.poll.interval.ms 每次消费的处理时间，两次poll操作之间最多间隔5分钟，没有发起poll，broker就默认它挂了，踢掉它，触发再均衡。
            * max.poll.records 每次消费的消息数，消费太多的话，处理不过来，5分钟内没poll第二次，也认为消费者挂了。
* 如果还不行，可能是消费者GC表现问题，可以去排查下gc日志。

## 为什么说分区数量就是消费者的最大数量？
* kafka的设计如此：一个分区只能被一个消费组的一个消费者消费。但是反之，消费组内的一个消费者可以消费多个分区。
* 这么设计的好处：（其实这个没有统一的答案，我自己的理解如下）
    * 一方面避免了很多复杂代码的编写，避免了很多竞争临界区的判断。架构越简单越健壮，适用性越广。
    * 可以灵活设置消费模式：发布订阅模式、队列模式。

## kafka提交方式的最佳实践是什么?
* 有什么提交方式：
    * 自动
    * 手动
        * 手动同步
        * 手动异步
* 最佳实践：
    手动异步提交+callback，失败后用手动同步提交

## 如何处理kafka的消息堆积？
* 方案1：增加分区，以便增加消费组内的消费者。但一般出现问题的时候，已经来不及增加分区了，分区内的消息已经是堆积如山了。这个方案只能算是提前预防。
* 方案2：临时队列。
    * 新建一个topic2，新建分区100个。
    * 修改消费者consumer代码，不再进行业务计算，直接搬运到新的分区topic2。
    * 这100个Partition可以有100个Consumer了，它们来处理原来的业务逻辑。如果之前只有5个consumer，那么现在提速20倍。

## kafka的三种消息投递语义？
* at most once 最多一次，消息可能会丢，但不会重复。这个自动提交即可，然后producer端配置参数acks=0，投递了就完事，不用在意结果。日志场景很合适。
* at least once 最少一次，消息不会丢，但可能重复。这个要取消自动提交，手动同步、异步提交均可。然后producer端配置参数acks=-1，保证一定落地。
* exactly once 有且只有一次，不丢失不重复。
    * 1、producer端配置 enable.idempotence = true，幂等性打开。
    * 2、producer向指定topic的partition发送消息时，携带一个自己维护的自增的Sequence Number，broker会比较，如果seq是比上次+1，就接受，否则不接受。只有上一条消息成功，这一条消息才能投递成功。

## kafka怎么保证高性能、高可用、高吞吐？
* 高可用：
    * 副本机制 + 分开机器存放broker
    * 选举机制，leader挂了会自动选举后成为新的leader，提供服务
* 高性能、高吞吐：
    * 1、页缓存：
        * Kafka并不太依赖JVM内存大小，而是主要利用Page Cache，如果使用应用层缓存（JVM堆内存），会增加GC负担，增加停顿时间和延迟，创建对象的开销也会比较高。读取操作可以直接在Page Cache上进行，如果消费和生产速度相当，甚至不需要通过物理磁盘直接交换数据，这是Kafka高吞吐量的一个重要原因。
        * 这么做还有一个优势，如果Kafka重启，JVM内的Cache会失效，Page Cache依然可用。
    * 2、零拷贝：
        * 零拷贝1：技术是指计算机执行操作时，CPU不需要先将数据从某处内存复制到另一个特定区域。这种技术通常用于通过网络传输文件时节省CPU周期和内存带宽。
        * 零拷贝2：减少数据拷贝次数，减少系统调用，实现 CPU 的零参与，彻底消除 CPU 在这方面的负载。
        * buffer = File.read;Socket.send(buffer) 两行代码解析：
            * 1、通过系统调用将文件数据读入到内核态Buffer（DMA拷贝）
            * 2、应用程序将内存态Buffer数据读入到用户态Buffer（CPU拷贝）
            * 3、用户程序通过Socket发送数据时将用户态Buffer数据拷贝到内核态Buffer（CPU拷贝）
            * 4、DMA拷贝将数据拷贝到NIC Buffer。
            * 5、上面发生了4次拷贝+4次上下文切换。
        * linux 2.4 内核的 sendfile和transferTo实现零拷贝，具体就不深究了。 
        * kafka 存在大量的网络数据持久化到磁盘（Producer到Broker），磁盘文件通过网络发送（Broker到Consumer）的过程，零拷贝技术提高了性能。
    * 3、磁盘顺序I/O：
        * Kafka的每条消息都是append的，不会从中间写入和删除消息，保证了磁盘的顺序访问。
    * 4、全异步：
        * kafka内部基本没有同步阻塞操作，调用了发送方法后立即返回，等待buffer满了以后交给轮询线程，发送和接收消息，复制数据也是都是通过NetworkClient封装的poll方式。
    * 5、批量操作：
        * 顺序I/O配合批量操作，能大幅度提高性能，至少2个数量级。写数据还能聚合、批量压缩、批量刷盘等。