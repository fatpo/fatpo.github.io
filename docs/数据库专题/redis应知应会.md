* **1、缓存有哪些类型？**
* **2、Redis持久化机制**
* **3、缓存雪崩、缓存穿透、缓存预热、缓存降级、缓存更新**
* **4、怎么发现redis热key**
* **5、Memcache与Redis的区别都有哪些？**
* **6、单线程的redis为什么这么快**
* **7、redis的数据类型，以及每种数据类型的使用场景**
* **8、redis的过期策略以及内存淘汰机制**
* **9、Redis为什么是单线程的**
* **10、Redis常见性能问题和解决方案？**
* **11、为什么Redis的操作是原子性的，怎么保证原子性的？**
* **12、Redis事务**
* **13、Redis怎么删除大key**
* **14、你觉得什么操作会让Redis阻塞**
* **15、Redis脑裂怎么办**
* **16、Zset底层结构是什么？**


## 1、缓存有哪些类型？
* 本地缓存
    * 开源Google Guava Cache（我们架构用这个）
    * 开源Ehcache
    * 也可以自己手写LRUMap
* 分布式缓存
    * Redis（我们架构用这个）
    * Memcache
    * Hbase（我们架构用这个）
* 多级缓存
    * 本地缓存性能最高，没有网络开销，但是存量小（看你的JVM堆内存多大了），各个本地缓存之间没有互通机制。
    * 分布式缓存伸缩性好，数据共享唯一，但是有网络开销，有序列化/反序列化开销，性能不如本地缓存。
    * 目前单一的缓存无法应对日益复杂的场景，大多数综合使用，同时使用 Guava Cache 和 Redis 和 Hbase的都是正常的。

## 2、Redis持久化机制
* RDB是Redis默认的持久化方式。
    * 按照一定的时间周期策略把内存的数据以快照的形式保存到硬盘的二进制文件。即Snapshot快照存储，对应产生的数据文件为dump.rdb，通过配置文件中的save参数来定义快照的周期。（ 快照可以是其所表示的数据的一个副本，也可以是数据的一个复制品。）
    * 实现：单独创建**fork()一个子进程**，将当前父进程的数据库数据复制到子进程的内存中，然后由子进程
      写入到临时文件中，持久化的过程结束了，再用这个临时文件替换上次的快照文件，然后子进程退出，
      内存释放。
    * bgsave配置：`save 900 1`, `save 300 10`，300秒内修改了10次，900秒内修改了1次，就触发一次bgsave。
      * 两个参数：
        * dirty计数器：记录上一次成功bgsave后到现在，数据进行了多少次修改。
        * lastsave：一个unix时间戳，记录上一次bgsave或save的时间。
      * 谁来执行：
        * serverCron是一个定期执行的程序，默认每隔100ms执行一次，每次serverCron会遍历所有的配置条件，满足就触发bgsave。然后清空dirty计数器和记录最新的lastsave时间戳。
* AOF：Redis会将每一个收到的写命令都通过Write函数追加到文件最后，类似于MySQL的binlog。当Redis重启是会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。
  * aof_buf缓冲区 的存在是为了提速，数据先写到aof_buf，再刷盘到磁盘文件。它有3种配置策略：
    * always：写一次aof_buf就刷一次盘，数据永远不丢失。
    * no：不主动刷盘，不主动调用fsync，交给操作系统自己控制（操作系统write请求先写到缓冲区，满了才fsync）。
    * everysec：同步的时候，和上次同步磁盘的时间超过一秒，就执行刷盘。最多只损失一秒数据。`折中做法`。
* 当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。

## 3、缓存雪崩、缓存穿透、缓存预热、缓存降级、缓存更新
* **缓存雪崩：**
    * 主要突出一个**崩**字，由于原有缓存失效，新缓存未到期间，导致大量的请求打到数据库，把数据库搞宕机后，导致与数据库有关联的服务都挂掉，这一系列连锁反应。
    * 解决方案：
        * 1、人为设置过期时间+random seconds，避免同一时间失效，让数据库来得及局部重建。
        * 2、访问数据库前，设计加锁或者加队列，保证不会有大量的线程对数据库一次性进行读写。
        * 3、二级缓存，假如本地JVM缓存，也是不错的解决方案。
* **缓存穿透：**
    * 主要突出一个**透**字，主要是数据库中没有信息，缓存自然也没有，请求每次都要去缓存查一次，再去数据库查一次。
    * 解决方案：
      * 1、`前端校验+后端vo校验`，尽可能减少垃圾数据，比如userId=-1这种，尽早报错，不要进入业务处理逻辑。
      * 2、`hash拦截`，百分百拦截，自己维护一个hash池子，如商品池子，进入业务逻辑前先过滤一下hash拦截，和布隆过滤器想法一致。
      * 3、`位图标记`，百分百拦截，类似hash，不过数据结构变成了bitmap，比hash更节省资源。
      * 4、`布隆过滤器`，做不到百分百拦截，所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。
      * 5、`空值缓存`，最简单粗暴的方案，如果确实没有信息，可以在redis设置一个NULL_STR之类的空值。
* **缓存击穿**
  * 这个意思是单个热key，突然到了ttl过期时间，大量请求直接杀到DB。主要是单个、热key。雪崩是多个key。
  * 解决方案：
    * 1、不要当多个请求同时操作数据库！弄一个分布式锁如redis setnx或者zk之类的，只放一个请求进去操作db。
    * 2、单机锁，如果服务器不多的话，分布式锁降级为单机锁也未尝不可，同时访问数据库的数量也不多。但是如果服务器数量很多，比如高达1000台，还是客观的压力。
    * 3、二级缓存： 本地缓存google guava cache+ redis 大批量副本key。
    * 4、热点数据就尽可能管理起来，不要设置过期时间。
* **缓存预热：**
    * 主要突出一个**预**字，当你要做什么活动时，如果预判到key很热，在上线前，提前手工把数据刷入缓存。
* **缓存降级：**
    * 降级的意思就是提供**有损**服务，尽可能保证核心接口的正常，非核心接口有损。
    * 如果真的缓存服务挂了，是为了防止Redis服务故障导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务降级策略。
    * 例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。    
* **缓存更新：**
    * 怎么更新缓存？这个问题其实争议很大。一般有三个策略：
        * <font color='red'>先更新数据库，再更新缓存</font>
            * 这是唯一没有争议的策略，因为首先就要排除它，它太容易发生并发竞争导致redis存在脏数据，而且可能存在很长一段时间，直到下一次更新。
        * <font color='red'>先删除缓存，再更新数据库</font>
            * 这里其实很容易发生竞争：
                * 1、A删除了缓存。
                * 2、B发现缓存不存在，查了数据库旧值。
                * 2、B把旧值设置到缓存。
                * 3、A更新了数据库。
            * 解决方案:
                * 延时双删，先删一次，再休眠1秒后再删一次。
        * <font color='red'>先更新数据库，再删除缓存</font>
            * 大佬背书：facebook也在论文《Scaling Memcache at Facebook》中提出，他们用的也是先更新数据库，再删缓存的策略。
            * 大佬背书：老外提出了一个缓存更新套路，名为《Cache-Aside pattern》，先更新数据库，再删除它。
            * 真的万无一失吗？并不是，我可以模拟一个场景：（但是因为读比写快很多，这个概率比"先删除缓存，再更新数据库"起来，算是非常非常低）
                * 1、缓存刚好失效。
                * 2、A请求查询数据库，得到一个旧值。
                * 3、B请求更新数据库。
                * 4、B请求删除缓存。
                * 5、A请求设置旧值到缓存。
            * 非要杠这个万分之一的概率怎么办：
                * 在这个万分之一的基础上，采用延时双删策略，先删除后，再异步过几秒删除一波。
            * 接着杠精说这个双删第二次删除失败怎么办：
                * 在这个万分之一的基础上，还要发生redis删除失败？？这概率。。
                * 那么就给这个key加一个ttl，即使失败也能自动过期。

## 4、怎么发现热key
* 1、凭借业务经验，进行预估哪些是热key，其实这个方法还是挺有可行性的。比如某商品在做秒杀，那这个商品的key就可以判断出是热key。缺点很明显，并非所有业务都能预估出哪些key是热key。    
* 2、在客户端进行收集，这个方式就是在操作redis之前，加入一行代码进行数据统计。那么这个数据统计的方式有很多种，也可以是给外部的通讯系统发送一个通知信息。缺点就是对客户端代码造成入侵。
* 3、在Proxy层做收集，收集所有的redis路过的key，但是缺点很明显，并非所有的redis集群架构都有proxy。 
* 4、用redis自带命令：
    * 比如redis-faina。但是该命令在高并发的条件下，有内存增暴增的隐患，还会降低redis的性能。
    * hotkeys参数，redis 4.0.3提供了redis-cli的热点key发现功能，执行redis-cli时加上–hotkeys选项即可。但是该参数在执行的时候，如果key比较多，执行起来比较慢。
* 5、自己抓包评估，或者有日志分析框架的，通过日志回流，写脚本去分析。

话说当我们发现热key后又应该如何？业界有两个做法：
* 1、二级缓存，JVM级别的（Google Guava Cache） + Redis，尽可能让它在内存中命中。
* 2、备份热key，因为集群架构只能把一个key打到一个节点上，可以提前把key的名字分成10个比如，key#1,key#2,key#10，尽可能分布到各个节点上。

## 5、Memcache与Redis的区别都有哪些？
* 1、存储方式 Memecache把数据**全部存在内存**之中，断电后会挂掉，数据不能超过内存大小。 Redis有部份存在硬盘上，redis可以持久化其数据。
* 2、数据支持类型 memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 ，提供list，set，zset，hash等数据结构的存储
* 3、使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。 Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。
* 4、value 值大小不同：Redis 一个String类型的value最大可以存储512M。list可以存21亿个元素，最大可以达到 1gb；memcache 只有 1mb。
* 5、redis的速度比memcached慢。
    * Redis作者的说法是，平均到单个核上的性能，在单条数据不大的情况下，Redis会更好。
    * 因为Redis是单线程的，只能使用一个核。而Memcached是多线程的，所以对一个实例来说，性能上肯定是Memcached占优势。
    * 因为Redis的单线程，导致所有IO也是串行化的，当单条数据太大，IO等待会费掉时间，而不是程序本身性能或者复杂度。
    * 因为Redis有更复杂的数据类型，所以很多操作必然会比Memcached的get set操作更耗时。
* 6、Redis支持数据的备份，即master-slave模式的数据备份。


## 6、单线程的redis为什么这么快？
* 基于内存
* 合理的线程模型
    * 主线程是单线程，避免了上下文切换、避免了线程竞争
    * I/O线程是多线程，提高I/O处理能力，减缓I/O成为性能瓶颈的压力
    * I/O多路复用
* 高效的数据结构
    * 压缩列表
    * SDS简单动态字符串： 字符串长度处理、空间预分配、惰性空间释放、二进制安全
    * 跳跃表
    * hash
* 合理的编码
    * String： 
        * int，embstr，raw， int（8字节长整型）/embstr（小于等于39字节字符串）/raw（大于39个字节字符串）。
        * 应用：共享session、分布式锁，计数器、限流。
    * Hash: 
        * ziplist，hashtable
        * 应用：缓存用户信息、item正排信息等。
        * 注意： hgetall（拿key的全部filed）、hscan（key的filed过多怕阻塞）、hmget（只拿key中某一个filed） 根据合适的业务使用。
    * List： 
        * ziplist，linkedlist
        * 应用：队列（lpush+rpop），栈结构（lpush+lpop），有限集合（lpush+ltrim），消息队列（lpush+brpop）。
    * Set：
        * intset（整数集合），hashtable
        * 应用：用户标签,生成随机数抽奖、社交需求。
    * ZSet: 
        * ziplist， skiplist
        * 应用：排行榜，社交需求（如用户点赞）。
* 虚拟内存机制
    * 虚拟内存机制就是暂时把不经常访问的数据(冷数据)从内存交换到磁盘中，从而腾出宝贵的内存空间用于其它需要访问的数据(热数据)。通过VM功能可以实现冷热数据分离，使热数据仍在内存中、冷数据保存到磁盘。这样就可以避免因为内存不足而造成访问速度下降的问题。

## 8、redis的过期策略以及内存淘汰机制

* 过期策略：
    * 定时删除：每一个key设置一个定时器跟踪，时间到了就马上删除。
    * 定期删除：每隔一段时间，就批量删除一波过期数据。
    * 惰性删除：过期了不管它，用到了，判断下过期时间，过期了就删除。   
* redis采用哪种过期策略？
    * 定期删除 + 惰性删除
* redis为什么没有定时删除：
    * 定时删除,用一个定时器来负责监视key, 过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key, 因此没有采用这一策略.

* 内存淘汰机制：
    * no-enviction：不采取任何策略，不要管，内存不够，写不进去自然会报错。
    * volatile-lru：从设置了expire的数据集中，找到最近最少使用的key，删除。
    * allkeys-lru：从全部的数据集中，找到最近最少使用的key，删除。
    * volatile-random：从设置了expire的数据集中，随机找一波key，删除。
    * allkeys-random：从全部的数据集中，随机找一波key，删除。
    * volatile-ttl: 仅淘汰设置了过期时间的键-，淘汰生存时间TTL(Time To Live)更小的键。
    * 如果一个redis数据库中的key没有设置expire，但是又配置了volatile-lru, volatile-random, volatile-ttl，那么它本质上就是 no-enviction策略。
    
* 面试官让你手写LRU？
    * 首先，全部写完要200行，细节还贼多，我要是当面试官，我就会让你按照你掌握的数据结构，写一个LRU。刚好java的 LinkedHashMap 本身就能根据时间来放置元素，我们在基础上增加一个剔除动作即可。
    ```java
      public class LRULinkedHashMap<K, V> extends LinkedHashMap<K, V> {
      
          private int capacity;
      
          LRULinkedHashMap(int capacity) {
              // 初始大小，0.75是装载因子，true是表示按照访问时间排序，被访问时，会自动把访问元素放到队尾
              super(capacity, 0.75f, true);
              //传入指定的缓存最大容量
              this.capacity = capacity;
          }
      
          /**
           * 实现LRU的关键方法，如果map里面的元素个数大于了缓存最大容量，则删除链表的顶端元素
           */
          @Override
          protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
              return size() > capacity;
          }
    }
  ```
    

## 9、为什么Redis是单线程？
* 官方回答：
    * Redis都是内存操作，CPU不是它的性能瓶颈，单线程架构简单，没有多线程切换的开销和竞争条件。果然还是那句话，越简单越健壮。
    * Redis采用队列，把并发操作变成了串行操作。

## 10、Redis常见性能问题和解决方案？
* Master不要开启任何的持久化操作，RDB内存快照和AOF日志文件。
* 如果真的有重要数据，在某一台slave开启 AOF 备份数据，策略设置为每秒同步一次。
* 保证主从在同一个局域网。
* 避免压力很大的主库增加从库，因为增加从库是有开销的。
* 主从复制不要网状，改为单向链表型结构。还是那句话，每多一个从库，开销都要增加。

## 11、为什么Redis的操作是原子性的，怎么保证原子性的？
* 事实上，就因为它是单线程，而且它提供的所有API都是原子操作，所以它具备了单个命令的原子性。
* 如果是多个命令的话，它并不能保证原子性。
* 别想事务了，如果你有多个key，集群模式下，大概率是分布在多台redis上面的，事务根本不好使。
* 事实上还是要用LUA脚本来打配合，才能保证原子性。

## 12、Redis事务？
* 通过 MULTI、EXEC、DISCARD和WATCH 是个原语实现的。
    * MULTI 命令用于开启一个事务，它总是返回OK。 MULTI后，客户端发送的任何命令都不会执行，而是放到一个执行队列中。
    * EXEC 执行队列中该事务的所有命令。
    * DISCARD 放弃事务，清空队列，退出事务状态。
    * WATCH 主要是提供CAS，可以监控一个或者多个key知道EXEC命令被执行，监控期间如果有key改动了，就不执行事务。
* redis事务时，执行命令出现问题，不支持回滚，而是继续执行剩下的命令。
* redis 事务中有一个错误的命令（拼写错误），那么整个事务不会执行。
* redis 事务中有一个错误的命令（执行错误），那么跳过错误，继续执行后面的正确命令。

## 13、Redis怎么删除大key?
* 能否直接删除？
  * 不可！因为redis是单线程的，一个大key的操作会出现阻塞，阻塞期间所有请求都会超时。请求越多，redis连接池耗尽越快，最后会拖垮依赖redis的线上服务，继而导致雪崩。
* 解决方案：
  * 1、在三更半夜的时候业务低谷期偷偷摸摸删除。（高端的场景往往只需要简单的操作）
  * 2、分批法：
      * hash：hscan
      * list：分批pop数据即可
      * set：`SPOP key [count]` 每次随机删除一批数据
      * zset：zremrangebyrank， `ZREMRANGEBYRANK key start stop`， 命令用于移除有序集中，指定排名(rank)区间内的所有成员。
  * 3、异步删除：
    * redis 4.0推出一个异步线程，用`unlink`代替del，redis会把key丢到异步线程，不会阻塞主线程。


## 14、你觉得什么操作会让Redis阻塞?
* 1、模糊查询`key *`，线上遍历全部keys，恐怖如斯。 
* 2、操作大key，写入大key要申请大量空间，删除大key要释放大量空间，都是相对耗时的操作。
* 3、复杂指令如 `sunion` 查询多个集合的并集，redis会合并数据、去重数据，对CPU和内存都是有一定的耗费，数据很多的时候会阻塞。
* 4、持久化AOF，有一个aof buf，可以配置3个刷盘策略，从不，永远，和每一秒，如果设置了always，刚好有大批量写请求，会导致短时间内大批量刷盘，也是耗时操作。
* 5、大批量key同时失效，如果并发很高的话，同时访问这么多数据，导致redis要惰性删除，大批量惰性删除也会导致阻塞。
* 6、redis内存不足，如果配置了淘汰策略，来了新增key，那么淘汰策略回去执行一波删除key操作，这个时候可能有阻塞。

## 15、Redis脑裂了怎么办
* 什么是脑裂？
  * master挂了，和其他的slave连接不上，但是master此时的客户端连接并不知情，还是会继续写数据，master也以为自己正常，就写成功。
  * 其他的slave发现master挂了后，国不可一日无君，就从slave中选了一个新的master出来，然后一部分其他客户端往新的master写数据。
  * 等老master恢复后，发现自己落后了，就变成slave，删除自己的数据，从新master拉数据，那么故障期间之前往老master写的数据都丢失了。
* 配置两个参数：
  * min-slaves-to-write，这是限制了主库最小能同步的从库数量，如果我们设置为1，老master如果失联了，没有连接任何从库，那么它的写请求会拒绝，返回错误信息给客户端。
  * min-slaves-max-lag，这是限制了主从复制的时候，从库往主库发送ack消息的最大延迟，比如设置了10秒，老master10秒内没收到slave的回复，也会拒绝写入，直接返回错误给客户端。


## 16、Zset底层结构是什么？
* zset在`元素个数<128`并且`每个元素长度<64字节`的时候，采用`压缩列表`，其它情况采用`跳表`。
* 压缩列表长什么样子：
  * 列表长度+尾部偏移量（可以快速到尾巴）+元素个数+若干个元素+结束标志。
* 为什么使用跳表而不是红黑树等平衡二叉树？
  * 虽然跳表和红黑树在查找时间复杂度都是O(logN)，但是：
    * 跳表更容易编码实现。
    * 跳表更容易操控索引层级，控制内存消耗。
    * 跳表更容易搞范围查询，这也是最核心的一个理由。