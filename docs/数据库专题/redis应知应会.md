* **1、缓存有哪些类型？**
* **2、Redis持久化机制**
* **3、缓存雪崩、缓存穿透、缓存预热、缓存降级、缓存更新**
* **4、怎么发现redis热key**
* **5、Memcache与Redis的区别都有哪些？**
* **6、单线程的redis为什么这么快**
* **7、redis的数据类型，以及每种数据类型的使用场景**
* **8、redis的过期策略以及内存淘汰机制**
* **9、Redis为什么是单线程的**
* **10、Redis常见性能问题和解决方案？**
* **11、为什么Redis的操作是原子性的，怎么保证原子性的？**
* **12、Redis事务**


## 1、缓存有哪些类型？
* 本地缓存
    * 开源Google Guava Cache（我们架构用这个）
    * 开源Ehcache
    * 也可以自己手写LRUMap
* 分布式缓存
    * Redis（我们架构用这个）
    * Memcache
    * Hbase（我们架构用这个）
* 多级缓存
    * 本地缓存性能最高，没有网络开销，但是存量小（看你的JVM堆内存多大了），各个本地缓存之间没有互通机制。
    * 分布式缓存伸缩性好，数据共享唯一，但是有网络开销，有序列化/反序列化开销，性能不如本地缓存。
    * 目前单一的缓存无法应对日益复杂的场景，大多数综合使用，同时使用 Guava Cache 和 Redis 和 Hbase的都是正常的。

## 2、Redis持久化机制
* RDB是Redis默认的持久化方式。
    * 按照一定的时间周期策略把内存的数据以快照的形式保存到硬盘的二进制文件。即Snapshot快照存储，对应产生的数据文件为dump.rdb，通过配置文件中的save参数来定义快照的周期。（ 快照可以是其所表示的数据的一个副本，也可以是数据的一个复制品。）
    * 实现：单独创建**fork()一个子进程**，将当前父进程的数据库数据复制到子进程的内存中，然后由子进程
      写入到临时文件中，持久化的过程结束了，再用这个临时文件替换上次的快照文件，然后子进程退出，
      内存释放。
* AOF：Redis会将每一个收到的写命令都通过Write函数追加到文件最后，类似于MySQL的binlog。当Redis重启是会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。
* 当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。

## 3、缓存雪崩、缓存穿透、缓存预热、缓存降级、缓存更新
* **缓存雪崩：**
    * 主要突出一个**崩**字，由于原有缓存失效，新缓存未到期间，导致大量的请求打到数据库，把数据库搞宕机后，导致与数据库有关联的服务都挂掉，这一系列连锁反应。
    * 解决方案：
        * 1、人为设置过期时间+random seconds，避免同一时间失效，让数据库来得及局部重建。
        * 2、访问数据库前，设计加锁或者加队列，保证不会有大量的线程对数据库一次性进行读写。
* **缓存穿透：**
    * 主要突出一个**透**字，主要是数据库中没有信息，缓存自然也没有，请求每次都要去缓存查一次，再去数据库查一次。
    * 解决方案：
        * 1、布隆过滤器，所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。
        * 2、最简单粗暴的方案：如果确实没有信息，可以在redis设置一个NULL_STR之类的空值。
* **缓存预热：**
    * 主要突出一个**预**字，当你要做什么活动时，如果预判到key很热，在上线前，提前手工把数据刷入缓存。
* **缓存降级：**
    * 降级的意思就是提供**有损**服务，尽可能保证核心接口的正常，非核心接口有损。
    * 如果真的缓存服务挂了，是为了防止Redis服务故障导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务降级策略。
    * 例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。    
* **缓存更新：**
    * 怎么更新缓存？这个问题其实争议很大。一般有三个策略：
        * <font color='red'>先更新数据库，再更新缓存</font>
            * 这是唯一没有争议的策略，因为首先就要排除它，它太容易发生并发竞争导致redis存在脏数据，而且可能存在很长一段时间，直到下一次更新。
        * <font color='red'>先删除缓存，再更新数据库</font>
            * 这里其实很容易发生竞争：
                * 1、A删除了缓存。
                * 2、B发现缓存不存在，查了数据库旧值。
                * 2、B把旧值设置到缓存。
                * 3、A更新了数据库。
            * 解决方案:
                * 延时双删，先删一次，再休眠1秒后再删一次。
        * <font color='red'>先更新数据库，再删除缓存</font>
            * 大佬背书：facebook也在论文《Scaling Memcache at Facebook》中提出，他们用的也是先更新数据库，再删缓存的策略。
            * 大佬背书：老外提出了一个缓存更新套路，名为《Cache-Aside pattern》，先更新数据库，再删除它。
            * 真的万无一失吗？并不是，我可以模拟一个场景：（但是因为读比写快很多，这个概率比"先删除缓存，再更新数据库"起来，算是非常非常低）
                * 1、缓存刚好失效。
                * 2、A请求查询数据库，得到一个旧值。
                * 3、B请求更新数据库。
                * 4、B请求删除缓存。
                * 5、A请求设置旧值到缓存。
            * 非要杠这个万分之一的概率怎么办：
                * 在这个万分之一的基础上，采用延时双删策略，先删除后，再异步过几秒删除一波。
            * 接着杠精说这个双删第二次删除失败怎么办：
                * 在这个万分之一的基础上，还要发生redis删除失败？？这概率。。
                * 那么就给这个key加一个ttl，即使失败也能自动过期。

## 4、怎么发现热key
* 1、凭借业务经验，进行预估哪些是热key，其实这个方法还是挺有可行性的。比如某商品在做秒杀，那这个商品的key就可以判断出是热key。缺点很明显，并非所有业务都能预估出哪些key是热key。    
* 2、在客户端进行收集，这个方式就是在操作redis之前，加入一行代码进行数据统计。那么这个数据统计的方式有很多种，也可以是给外部的通讯系统发送一个通知信息。缺点就是对客户端代码造成入侵。
* 3、在Proxy层做收集，收集所有的redis路过的key，但是缺点很明显，并非所有的redis集群架构都有proxy。 
* 4、用redis自带命令：
    * 比如redis-faina。但是该命令在高并发的条件下，有内存增暴增的隐患，还会降低redis的性能。
    * hotkeys参数，redis 4.0.3提供了redis-cli的热点key发现功能，执行redis-cli时加上–hotkeys选项即可。但是该参数在执行的时候，如果key比较多，执行起来比较慢。
* 5、自己抓包评估，或者有日志分析框架的，通过日志回流，写脚本去分析。

话说当我们发现热key后又应该如何？业界有两个做法：
* 1、二级缓存，JVM级别的（Google Guava Cache） + Redis，尽可能让它在内存中命中。
* 2、备份热key，因为集群架构只能把一个key打到一个节点上，可以提前把key的名字分成10个比如，key#1,key#2,key#10，尽可能分布到各个节点上。

## 5、Memcache与Redis的区别都有哪些？
* 1、存储方式 Memecache把数据**全部存在内存**之中，断电后会挂掉，数据不能超过内存大小。 Redis有部份存在硬盘上，redis可以持久化其数据。
* 2、数据支持类型 memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 ，提供list，set，zset，hash等数据结构的存储
* 3、使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。 Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。
* 4、value 值大小不同：Redis 一个String类型的value最大可以存储512M。list可以存21亿个元素，最大可以达到 1gb；memcache 只有 1mb。
* 5、redis的速度比memcached慢。
    * Redis作者的说法是，平均到单个核上的性能，在单条数据不大的情况下，Redis会更好。
    * 因为Redis是单线程的，只能使用一个核。而Memcached是多线程的，所以对一个实例来说，性能上肯定是Memcached占优势。
    * 因为Redis的单线程，导致所有IO也是串行化的，当单条数据太大，IO等待会费掉时间，而不是程序本身性能或者复杂度。
    * 因为Redis有更复杂的数据类型，所以很多操作必然会比Memcached的get set操作更耗时。
* 6、Redis支持数据的备份，即master-slave模式的数据备份。


## 6、单线程的redis为什么这么快？
* 基于内存
* 合理的线程模型
    * 主线程是单线程，避免了上下文切换、避免了线程竞争
    * I/O线程是多线程，提高I/O处理能力，减缓I/O成为性能瓶颈的压力
    * I/O多路复用
* 高效的数据结构
    * 压缩列表
    * SDS简单动态字符串： 字符串长度处理、空间预分配、惰性空间释放、二进制安全
    * 跳跃表
    * hash
* 合理的编码
    * String： 
        * int，embstr，raw， int（8字节长整型）/embstr（小于等于39字节字符串）/raw（大于39个字节字符串）。
        * 应用：共享session、分布式锁，计数器、限流。
    * Hash: 
        * ziplist，hashtable
        * 应用：缓存用户信息、item正排信息等。
        * 注意： hgetall（拿key的全部filed）、hscan（key的filed过多怕阻塞）、hmget（只拿key中某一个filed） 根据合适的业务使用。
    * List： 
        * ziplist，linkedlist
        * 应用：队列（lpush+rpop），栈结构（lpush+lpop），有限集合（lpush+ltrim），消息队列（lpush+brpop）。
    * Set：
        * intset（整数集合），hashtable
        * 应用：用户标签,生成随机数抽奖、社交需求。
    * ZSet: 
        * ziplist， skiplist
        * 应用：排行榜，社交需求（如用户点赞）。
* 虚拟内存机制
    * 虚拟内存机制就是暂时把不经常访问的数据(冷数据)从内存交换到磁盘中，从而腾出宝贵的内存空间用于其它需要访问的数据(热数据)。通过VM功能可以实现冷热数据分离，使热数据仍在内存中、冷数据保存到磁盘。这样就可以避免因为内存不足而造成访问速度下降的问题。

## 8、redis的过期策略以及内存淘汰机制

* 过期策略：
    * 定时删除：每一个key设置一个定时器跟踪，时间到了就马上删除。
    * 定期删除：每隔一段时间，就批量删除一波过期数据。
    * 惰性删除：过期了不管它，用到了，判断下过期时间，过期了就删除。   
* redis采用哪种过期策略？
    * 定期删除 + 惰性删除
* redis为什么没有定时删除：
    * 定时删除,用一个定时器来负责监视key, 过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key, 因此没有采用这一策略.

* 内存淘汰机制：
    * no-enviction：不采取任何策略，不要管，内存不够，写不进去自然会报错。
    * volatile-lru：从设置了expire的数据集中，找到最近最少使用的key，删除。
    * allkeys-lru：从全部的数据集中，找到最近最少使用的key，删除。
    * volatile-random：从设置了expire的数据集中，随机找一波key，删除。
    * allkeys-random：从全部的数据集中，随机找一波key，删除。
    * volatile-ttl: 仅淘汰设置了过期时间的键-，淘汰生存时间TTL(Time To Live)更小的键。
    * 如果一个redis数据库中的key没有设置expire，但是又配置了volatile-lru, volatile-random, volatile-ttl，那么它本质上就是 no-enviction策略。
    
* 面试官让你手写LRU？
    * 首先，全部写完要200行，细节还贼多，我要是当面试官，我就会让你按照你掌握的数据结构，写一个LRU。刚好java的 LinkedHashMap 本身就能根据时间来放置元素，我们在基础上增加一个剔除动作即可。
    ```java
      public class LRULinkedHashMap<K, V> extends LinkedHashMap<K, V> {
      
          private int capacity;
      
          LRULinkedHashMap(int capacity) {
              // 初始大小，0.75是装载因子，true是表示按照访问时间排序，被访问时，会自动把访问元素放到队尾
              super(capacity, 0.75f, true);
              //传入指定的缓存最大容量
              this.capacity = capacity;
          }
      
          /**
           * 实现LRU的关键方法，如果map里面的元素个数大于了缓存最大容量，则删除链表的顶端元素
           */
          @Override
          protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
              return size() > capacity;
          }
    }
  ```
    

## 9、为什么Redis是单线程？
* 官方回答：
    * Redis都是内存操作，CPU不是它的性能瓶颈，单线程架构简单，没有多线程切换的开销和竞争条件。果然还是那句话，越简单越健壮。
    * Redis采用队列，把并发操作变成了串行操作。

## 10、Redis常见性能问题和解决方案？
* Master不要开启任何的持久化操作，RDB内存快照和AOF日志文件。
* 如果真的有重要数据，在某一台slave开启 AOF 备份数据，策略设置为每秒同步一次。
* 保证主从在同一个局域网。
* 避免压力很大的主库增加从库，因为增加从库是有开销的。
* 主从复制不要网状，改为单向链表型结构。还是那句话，每多一个从库，开销都要增加。

## 11、为什么Redis的操作是原子性的，怎么保证原子性的？
* 事实上，就因为它是单线程，而且它提供的所有API都是原子操作，所以它具备了单个命令的原子性。
* 如果是多个命令的话，它并不能保证原子性。
* 别想事务了，如果你有多个key，集群模式下，大概率是分布在多台redis上面的，事务根本不好使。
* 事实上还是要用LUA脚本来打配合，才能保证原子性。

## 12、Redis事务？
* 通过 MULTI、EXEC、DISCARD和WATCH 是个原语实现的。
    * MULTI 命令用于开启一个事务，它总是返回OK。 MULTI后，客户端发送的任何命令都不会执行，而是放到一个执行队列中。
    * EXEC 执行队列中该事务的所有命令。
    * DISCARD 放弃事务，清空队列，退出事务状态。
    * WATCH 主要是提供CAS，可以监控一个或者多个key知道EXEC命令被执行，监控期间如果有key改动了，就不执行事务。
* redis事务时，执行命令出现问题，不支持回滚，而是继续执行剩下的命令。
* redis 事务中有一个错误的命令（拼写错误），那么整个事务不会执行。
* redis 事务中有一个错误的命令（执行错误），那么跳过错误，继续执行后面的正确命令。
